<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0"><channel><title>De Motu (signal processing)</title><link>http://demotu.github.io/</link><description></description><language>en</language><lastBuildDate>Fri, 18 Jul 2014 02:10:38 GMT</lastBuildDate><generator>http://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Prediction ellipse and prediction ellipsoid</title><link>http://demotu.github.io/posts/prediction-ellipse-ellipsoid.html</link><dc:creator>Marcos</dc:creator><description>&lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;To describe the dispersion of data or to make a prediction for a sample, we can calculate a &lt;a href="http://en.wikipedia.org/wiki/Prediction_interval"&gt;prediction interval&lt;/a&gt;. For the specific case of a univariate random variable, see &lt;a href="http://demotu.github.io/posts/confidence-prediction-intervals.html"&gt;Confidence and prediction intervals&lt;/a&gt;. For a multivariate random variable, we need to calculate a prediction ellipse (bivariate) or ellipsoid (trivariate):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The 95% prediction ellipse (or ellipsoid) is a prediction interval for a sample of a bivariate (or trivariate) random variable such that there is 95% of probability that a new observation will lie inside the ellipse (or ellipsoid) &lt;a href="http://www.jstor.org/stable/2282774"&gt;(Chew, 1966)&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The 95% prediction interval (a p-dimensional ellipsoid) for a sample of a multivariate random variable with &lt;span class="math"&gt;\(p\)&lt;/span&gt; dimensions and size &lt;span class="math"&gt;\(n\)&lt;/span&gt; from a population with normal distribution is given by the following probabilistic bounds which holds 95% of the time (Chew, 1966):&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\[ (x_{n+1}-\bar{x})'\: S^{-1} (x_{n+1}-\bar{x}) \leq \frac{F_{(0.95,\: p,\: n-p)}(n-1)\:p\:(n+1)}{n\:(n-p)} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class="math"&gt;\(x_{n+i}\)&lt;/span&gt; (with dimension &lt;span class="math"&gt;\(p\)&lt;/span&gt;) is the new observation for which we want to calculate the prediction interval; &lt;span class="math"&gt;\(F\)&lt;/span&gt; is the &lt;a href="http://en.wikipedia.org/wiki/F-distribution"&gt;F-distribution&lt;/a&gt;; &lt;span class="math"&gt;\(\bar{x}\)&lt;/span&gt; is the sample mean (with dimension &lt;span class="math"&gt;\(p\)&lt;/span&gt;), and &lt;span class="math"&gt;\(S\)&lt;/span&gt; is the &lt;a href="http://en.wikipedia.org/wiki/Sample_mean_and_sample_covariance"&gt;sample covariance matrix&lt;/a&gt; defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\[ S_{j,k} = \frac{1}{n-1}\sum_{i=1}^{n}(x_{ij}-\bar{x}_j)(x_{ik}-\bar{x}_k) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The function &lt;code&gt;ellipseoid.py&lt;/code&gt; (code at the end of this text) calculates the prediction ellipse or ellipsoid, some related parameters, and plots the results for a given multivariate random variable. The function signature is:&lt;/p&gt;
&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;area_vol, saxes, angles, center, R = ellipseoid(P, y=&lt;span class="ot"&gt;None&lt;/span&gt;, z=&lt;span class="ot"&gt;None&lt;/span&gt;, pvalue=.&lt;span class="dv"&gt;95&lt;/span&gt;,
                                                units=&lt;span class="ot"&gt;None&lt;/span&gt;, show=&lt;span class="ot"&gt;True&lt;/span&gt;, ax=&lt;span class="ot"&gt;None&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before showing how to use this code, let's look a bit more at the statistical principles behind the estimation of a prediction interval.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://demotu.github.io/posts/prediction-ellipse-ellipsoid.html"&gt;Read more…&lt;/a&gt; (11 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>python</category><category>signal processing</category><category>statistics</category><guid>http://demotu.github.io/posts/prediction-ellipse-ellipsoid.html</guid><pubDate>Thu, 17 Jul 2014 02:30:00 GMT</pubDate></item><item><title>Confidence and prediction intervals</title><link>http://demotu.github.io/posts/confidence-prediction-intervals.html</link><dc:creator>Marcos</dc:creator><description>&lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;For a finite univariate random variable with a normal probability distribution, the mean &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; (a measure of central tendency) and variance &lt;span class="math"&gt;\(\sigma^2\)&lt;/span&gt; (a measure of dispersion) of a population are the well known formulas:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\[ \mu = \frac{1}{N}\sum_{i=1}^{N} x_i \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\[ \sigma^2 = \frac{1}{N}\sum_{i=1}^{N} (x_i - \mu)^2 \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For a more general case, a continuous univariate random variable &lt;span class="math"&gt;\(x\)&lt;/span&gt; with &lt;a href="http://en.wikipedia.org/wiki/Probability_density_function"&gt;probability density function&lt;/a&gt; (pdf), &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt;, the mean and variance of a population are:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\[ \mu = \int_{\infty}^{\infty} x f(x)\: dx \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\[ \sigma^2 = \int_{\infty}^{\infty} (x-\mu)^2 f(x)\: dx \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The pdf is a function that describes the relative likelihood for the random variable to take on a given value.&lt;br&gt;Mean and variance are the first and second central moments of a random variable. The standard deviation &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; of the population is the square root of the variance.&lt;/p&gt;
&lt;p&gt;The &lt;a href="http://en.wikipedia.org/wiki/Normal_distribution"&gt;normal (or Gaussian) distribution&lt;/a&gt; is a very common and useful distribution, also because of the &lt;a href="http://en.wikipedia.org/wiki/Central_limit_theorem"&gt;central limit theorem&lt;/a&gt;, which states that for a sufficiently large number of samples (each with many observations) of an independent random variable with an arbitrary probability distribution, the means of the samples will have a normal distribution. That is, even if the underlying probability distribution of a random variable is not normal, if we sample enough this variable, the means of the set of samples will have a normal distribution.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://demotu.github.io/posts/confidence-prediction-intervals.html"&gt;Read more…&lt;/a&gt; (8 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>python</category><category>signal processing</category><category>statistics</category><guid>http://demotu.github.io/posts/confidence-prediction-intervals.html</guid><pubDate>Thu, 17 Jul 2014 02:00:00 GMT</pubDate></item><item><title>Detection of changes with the CUSUM algorithm</title><link>http://demotu.github.io/posts/detect-cusum.html</link><dc:creator>Marcos</dc:creator><description>&lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Change_detection"&gt;Change detection&lt;/a&gt; refers to procedures to identify abrupt changes in a phenomenon (Basseville and Nikiforov 1993, Gustafsson 2000). By abrupt change it is meant any difference in relation to previous known data faster than expected of some characteristic of the data such as amplitude, mean, variance, frequency, etc. The &lt;a href="http://en.wikipedia.org/wiki/CUSUM"&gt;Cumulative sum (CUSUM)&lt;/a&gt; algorithm is a classical technique for monitoring changes. One form of implementing the CUSUM algorithm involves the calculation of the cumulative sum of positive and negative changes &lt;span class="math"&gt;\((g_t^+\)&lt;/span&gt; and &lt;span class="math"&gt;\(g_t^-)\)&lt;/span&gt; in the data (&lt;span class="math"&gt;\(x\)&lt;/span&gt;) and comparison to a &lt;span class="math"&gt;\(threshold\)&lt;/span&gt;. When this threshold is exceeded a change is detected &lt;span class="math"&gt;\((t_{talarm})\)&lt;/span&gt; and the cumulative sum restarts from zero. To avoid the detection of a change in absence of an actual change or a slow drift, this algorithm also depends on a parameter &lt;span class="math"&gt;\(drift\)&lt;/span&gt; for drift correction. The CUSUM algorithm can be expressed as:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\[ \begin{array}{l l} 
\left\{ \begin{array}{l l} 
s[t] = x[t] - x[t-1] \\
g^+[t] = max\left(g^+[t-1] + s[t]-drift,\; 0\right) \\
g^-[t] = max\left(g^-[t-1] - s[t]-drift,\; 0\right)
\end{array} \right. \\
\; if \;\;\; g^+[t] &amp;gt; threshold \;\;\; or \;\;\;  g^-[t] &amp;gt; threshold: \\
\left\{ \begin{array}{l l} 
t_{talarm}=t \\
g^+[t] = 0 \\
g^-[t] = 0 
\end{array} \right.
\end{array} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The function &lt;code&gt;detect_cusum.py&lt;/code&gt; (code at the end of this text) implements the CUSUM algorithm and a procedure to calculate the ending of the detected change. The function signature is:&lt;/p&gt;
&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;ta, tai, taf, amp = detect_cusum(x, threshold=&lt;span class="dv"&gt;1&lt;/span&gt;, drift=&lt;span class="dv"&gt;0&lt;/span&gt;,
                                 ending=&lt;span class="ot"&gt;False&lt;/span&gt;, show=&lt;span class="ot"&gt;True&lt;/span&gt;, ax=&lt;span class="ot"&gt;None&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="http://demotu.github.io/posts/detect-cusum.html"&gt;Read more…&lt;/a&gt; (5 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>python</category><category>signal detection</category><category>signal processing</category><guid>http://demotu.github.io/posts/detect-cusum.html</guid><pubDate>Wed, 09 Jul 2014 21:30:00 GMT</pubDate></item><item><title>Detection of onset in data</title><link>http://demotu.github.io/posts/detect-onset.html</link><dc:creator>Marcos</dc:creator><description>&lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;One of the simplest methods to automatically detect or identify the change or occurrence of a particular event in the data, for example, its beginning and ending, or simply the data onset, is based on amplitude threshold, where the signal is considered to be 'on' when it is above a certain threshold. This threshold can be proportional to the amplitude of the baseline (the part of the data that we know there is no real signal, only noise). For instance, a threshold equals to two or three times the standard deviation of the baseline is a common procedure employed in the analysis of electromyographic data. Other way to set the threshold would be as a percentage value of the maximum or peak of the data. For instance, in movement analysis it's common to define the onset period as the signal above 5% of the peak velocity of the investigated movement.&lt;/p&gt;
&lt;p&gt;The function &lt;code&gt;detect_onset.py&lt;/code&gt; (code at the end of this text) implements such onset detection based on the amplitude-threshold method with a parameter to specify a minimum number of samples above threshold to detect as onset and another parameter to specify the minimum number of samples (continuous or not) below threshold that will be ignored in the detection of data greater or equal to threshold (to avoid the detection of spikes or transients in the data). The function signature is:&lt;/p&gt;
&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;inds = detect_onset(x, threshold=&lt;span class="dv"&gt;0&lt;/span&gt;, n_above=&lt;span class="dv"&gt;1&lt;/span&gt;, n_below=&lt;span class="dv"&gt;0&lt;/span&gt;,
                    show=&lt;span class="ot"&gt;False&lt;/span&gt;, ax=&lt;span class="ot"&gt;None&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let's see how &lt;code&gt;detect_onset.py&lt;/code&gt; works; first let's import the necessary Python libraries and configure the environment:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://demotu.github.io/posts/detect-onset.html"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>python</category><category>signal detection</category><category>signal processing</category><guid>http://demotu.github.io/posts/detect-onset.html</guid><pubDate>Wed, 09 Jul 2014 21:00:00 GMT</pubDate></item><item><title>Detection of peaks in data</title><link>http://demotu.github.io/posts/detect-peaks-in-data.html</link><dc:creator>Marcos</dc:creator><description>&lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;One way to detect peaks (local maxima) or valleys (local minima) in data is to use the property that a peak (or valley) must be greater (or smaller) than its immediate neighbors. The function &lt;code&gt;detect_peaks.py&lt;/code&gt; (code at the end of this notebook) detects peaks (or valleys) based on this feature and other characteristics. The function signature is:&lt;/p&gt;
&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;ind = detect_peaks(x, mph=&lt;span class="ot"&gt;None&lt;/span&gt;, mpd=&lt;span class="dv"&gt;1&lt;/span&gt;, threshold=&lt;span class="dv"&gt;0&lt;/span&gt;, edge=&lt;span class="st"&gt;'rising'&lt;/span&gt;,
                   kpsh=&lt;span class="ot"&gt;False&lt;/span&gt;, valley=&lt;span class="ot"&gt;False&lt;/span&gt;, show=&lt;span class="ot"&gt;False&lt;/span&gt;, ax=&lt;span class="ot"&gt;None&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The parameters &lt;code&gt;mph&lt;/code&gt;, &lt;code&gt;mpd&lt;/code&gt;, and &lt;code&gt;threshold&lt;/code&gt; follow the convention of the Matlab function &lt;code&gt;findpeaks.m&lt;/code&gt;.&lt;br&gt;Let's see how to use &lt;code&gt;detect_peaks.py&lt;/code&gt;; first let's import the necessary Python libraries and configure the environment:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://demotu.github.io/posts/detect-peaks-in-data.html"&gt;Read more…&lt;/a&gt; (5 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>python</category><category>signal detection</category><category>signal processing</category><guid>http://demotu.github.io/posts/detect-peaks-in-data.html</guid><pubDate>Tue, 08 Jul 2014 18:00:00 GMT</pubDate></item></channel></rss>