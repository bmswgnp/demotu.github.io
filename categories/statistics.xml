<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>De Motu (statistics)</title><link>http://demotu.github.io/</link><description></description><language>en</language><lastBuildDate>Mon, 21 Jul 2014 18:33:35 GMT</lastBuildDate><generator>http://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Prediction ellipse and prediction ellipsoid</title><link>http://demotu.github.io/posts/prediction-ellipse-ellipsoid.html</link><dc:creator>Marcos</dc:creator><description>&lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;To describe the dispersion of data or to make a prediction for a sample, we can calculate a &lt;a href="http://en.wikipedia.org/wiki/Prediction_interval"&gt;prediction interval&lt;/a&gt;. For the specific case of a univariate random variable, see &lt;a href="http://demotu.github.io/posts/confidence-prediction-intervals.html"&gt;Confidence and prediction intervals&lt;/a&gt;. For a multivariate random variable, we need to calculate a prediction ellipse (bivariate) or ellipsoid (trivariate):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The 95% prediction ellipse (or ellipsoid) is a prediction interval for a sample of a bivariate (or trivariate) random variable such that there is 95% of probability that a new observation will lie inside the ellipse (or ellipsoid) &lt;a href="http://www.jstor.org/stable/2282774"&gt;(Chew, 1966)&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The 95% prediction interval (a p-dimensional ellipsoid) for a sample of a multivariate random variable with &lt;span class="math"&gt;\(p\)&lt;/span&gt; dimensions and size &lt;span class="math"&gt;\(n\)&lt;/span&gt; from a population with normal distribution is given by the following probabilistic bounds which holds 95% of the time (Chew, 1966):&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\[ (x_{n+1}-\bar{x})'\: S^{-1} (x_{n+1}-\bar{x}) \leq \frac{F_{(0.95,\: p,\: n-p)}(n-1)\:p\:(n+1)}{n\:(n-p)} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class="math"&gt;\(x_{n+i}\)&lt;/span&gt; (with dimension &lt;span class="math"&gt;\(p\)&lt;/span&gt;) is the new observation for which we want to calculate the prediction interval; &lt;span class="math"&gt;\(F\)&lt;/span&gt; is the &lt;a href="http://en.wikipedia.org/wiki/F-distribution"&gt;F-distribution&lt;/a&gt;; &lt;span class="math"&gt;\(\bar{x}\)&lt;/span&gt; is the sample mean (with dimension &lt;span class="math"&gt;\(p\)&lt;/span&gt;), and &lt;span class="math"&gt;\(S\)&lt;/span&gt; is the &lt;a href="http://en.wikipedia.org/wiki/Sample_mean_and_sample_covariance"&gt;sample covariance matrix&lt;/a&gt; defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\[ S_{j,k} = \frac{1}{n-1}\sum_{i=1}^{n}(x_{ij}-\bar{x}_j)(x_{ik}-\bar{x}_k) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The function &lt;code&gt;ellipseoid.py&lt;/code&gt; (code at the end of this text) calculates the prediction ellipse or ellipsoid, some related parameters, and plots the results for a given multivariate random variable. The function signature is:&lt;/p&gt;
&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;area_vol, saxes, angles, center, R = ellipseoid(P, y=&lt;span class="ot"&gt;None&lt;/span&gt;, z=&lt;span class="ot"&gt;None&lt;/span&gt;, pvalue=.&lt;span class="dv"&gt;95&lt;/span&gt;,
                                                units=&lt;span class="ot"&gt;None&lt;/span&gt;, show=&lt;span class="ot"&gt;True&lt;/span&gt;, ax=&lt;span class="ot"&gt;None&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before showing how to use this code, let's look a bit more at the statistical principles behind the estimation of a prediction interval.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://demotu.github.io/posts/prediction-ellipse-ellipsoid.html"&gt;Read more…&lt;/a&gt; (11 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>python</category><category>signal processing</category><category>statistics</category><guid>http://demotu.github.io/posts/prediction-ellipse-ellipsoid.html</guid><pubDate>Thu, 17 Jul 2014 02:30:00 GMT</pubDate></item><item><title>Confidence and prediction intervals</title><link>http://demotu.github.io/posts/confidence-prediction-intervals.html</link><dc:creator>Marcos</dc:creator><description>&lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;For a finite univariate random variable with a normal probability distribution, the mean &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; (a measure of central tendency) and variance &lt;span class="math"&gt;\(\sigma^2\)&lt;/span&gt; (a measure of dispersion) of a population are the well known formulas:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\[ \mu = \frac{1}{N}\sum_{i=1}^{N} x_i \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\[ \sigma^2 = \frac{1}{N}\sum_{i=1}^{N} (x_i - \mu)^2 \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For a more general case, a continuous univariate random variable &lt;span class="math"&gt;\(x\)&lt;/span&gt; with &lt;a href="http://en.wikipedia.org/wiki/Probability_density_function"&gt;probability density function&lt;/a&gt; (pdf), &lt;span class="math"&gt;\(f(x)\)&lt;/span&gt;, the mean and variance of a population are:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\[ \mu = \int_{\infty}^{\infty} x f(x)\: dx \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\[ \sigma^2 = \int_{\infty}^{\infty} (x-\mu)^2 f(x)\: dx \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The pdf is a function that describes the relative likelihood for the random variable to take on a given value.&lt;br&gt;Mean and variance are the first and second central moments of a random variable. The standard deviation &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; of the population is the square root of the variance.&lt;/p&gt;
&lt;p&gt;The &lt;a href="http://en.wikipedia.org/wiki/Normal_distribution"&gt;normal (or Gaussian) distribution&lt;/a&gt; is a very common and useful distribution, also because of the &lt;a href="http://en.wikipedia.org/wiki/Central_limit_theorem"&gt;central limit theorem&lt;/a&gt;, which states that for a sufficiently large number of samples (each with many observations) of an independent random variable with an arbitrary probability distribution, the means of the samples will have a normal distribution. That is, even if the underlying probability distribution of a random variable is not normal, if we sample enough this variable, the means of the set of samples will have a normal distribution.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://demotu.github.io/posts/confidence-prediction-intervals.html"&gt;Read more…&lt;/a&gt; (8 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>python</category><category>signal processing</category><category>statistics</category><guid>http://demotu.github.io/posts/confidence-prediction-intervals.html</guid><pubDate>Thu, 17 Jul 2014 02:00:00 GMT</pubDate></item></channel></rss>